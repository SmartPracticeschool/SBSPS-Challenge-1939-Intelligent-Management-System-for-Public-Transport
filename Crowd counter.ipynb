{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install opencv-python", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Collecting opencv-python\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c2/e9cf54ae5b1102020ef895866a67cb2e1aef72f16dd1fde5b5fb1495ad9c/opencv_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (28.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28.2MB 5.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from opencv-python) (1.15.4)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.2.0.34\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install imutils", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Collecting imutils\n  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_03d269dcb9d842f3a697a2cdf4a866f1 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='hTUK0p_OunykX2zCo2LOvZiEuzyrBUZEqEIbKf6E2FRv',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_03d269dcb9d842f3a697a2cdf4a866f1.get_object(Bucket='trackingsystem-donotdelete-pr-owbbmha0bszpwz', Key='HAAR.xml')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_2 = client_03d269dcb9d842f3a697a2cdf4a866f1.get_object(Bucket='trackingsystem-donotdelete-pr-owbbmha0bszpwz', Key='Crowd.avi')['Body']\n# add missing __iter__ method so pandas accepts body as file-like object\nif not hasattr(streaming_body_2, \"__iter__\"): streaming_body_2.__iter__ = types.MethodType( __iter__, streaming_body_2 ) \n", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import argparse\nimport cv2\nimport os\nimport time\nimport imutils\nimport numpy as np\n\nENTERED_STRING = \"ENTERED_THE_AREA\"\nLEFT_AREA_STRING = \"LEFT_THE_AREA\"\nNO_CHANGE_STRING = \"STAY_IN_AREA\"\nLOWEST_CLOSEST_DISTANCE_THRESHOLD = 100\nSZ_LIMIT1 = 120\nSZ_LIMIT2 = 250\nline_point1 = (50, 300)\nline_point2 = (640 - 50, 300)\ntop_cascade = cv2.CascadeClassifier('HAAR.xml')\n_DEBUG_ = False\n_OUTPUT_ = False\n\n", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "class Person:\n    positions = []\n    isCounted = False\n    disappear_count = 0\n\n    def __init__(self, position):\n        self.positions = [position]\n\n    def update_position(self, new_position):\n        self.positions.append(new_position)\n        if len(self.positions) > 100:\n            self.positions.pop(0)\n\n    def on_opposite_sides(self, y_coord):\n        val1 = (self.positions[-2][1] > y_coord) and (self.positions[-1][1] <= y_coord)\n        val2 = (self.positions[-2][1] <= y_coord) and (self.positions[-1][1] > y_coord)\n        return val1 or val2\n\n", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "    def did_cross_line(self, y_coord):\n        if self.on_opposite_sides(y_coord):\n            # if abs(self.positions[-1][1] - line_point1[1]) > 50:\n            #     return NO_CHANGE_STRING\n            if self.positions[-1][1] < line_point1[1]:\n                if not self.isCounted:\n                    # self.isCounted = True\n                    return ENTERED_STRING\n                else:\n                    self.disappear_count += 1\n                    return NO_CHANGE_STRING\n            else:\n                if not self.isCounted:\n                    # self.isCounted = True\n                    return LEFT_AREA_STRING\n                else:\n                    self.disappear_count += 1\n                    return NO_CHANGE_STRING\n        else:\n            self.disappear_count += 1\n            return NO_CHANGE_STRING\n\n", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "    def distance_from_last_x_positions(self, new_position, x):\n        (x1, y1) = self.positions[-1]\n        (x2, y2) = new_position\n        return int(np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2))\n        \n        total = [0, 0]\n        z = x\n        while z > 0:\n            if len(self.positions) > z:\n                total[0] += self.positions[-(z + 1)][0]\n                total[1] += self.positions[-(z + 1)][1]\n            else:\n                x -= 1\n            z -= 1\n        if total[0] < 1 or total[1] < 1:\n            return abs(self.positions[0][0] - new_position[0]) + abs(self.positions[0][1] - new_position[1])\n        total[0] = total[0] / x\n        total[1] = total[1] / x\n\n        return abs(new_position[0] - total[0]) + abs(new_position[1] - total[1])\n        \n\n\n", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_video():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-v\", \"--video\", default=\"video/Crowd.avi\", help=\"path to the video file\")\n    args = vars(ap.parse_args())\n\n    # get video from webcam\n    if args.get(\"video\", None) is None:\n        camera = cv2.VideoCapture(0)\n        time.sleep(0.25)\n        return camera\n    # get video from file\n    else:\n        return cv2.VideoCapture(args[\"video\"])\n\n\n", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def testNeighbourIn(x, y, x0, y0, d):\n    dis = (x - x0) ** 2 + (y - y0) ** 2\n    if dis < d ** 2:\n        return True\n    return False\n\n\ndef checkFixed(prvs, curs):\n    result = []\n    if len(prvs) == 0:\n        return result\n    for box in curs:\n        [cx, cy, _] = box\n        is_again = False\n        for new_box in prvs:\n            [cx1, cy1, _] = new_box\n            if testNeighbourIn(cx, cy, cx1, cy1, 20) or not testNeighbourIn(cx, cy, cx1, cy1, 40):\n                is_again = True\n                break\n        if not is_again:\n            result.append(box)\n    return result\n\n\n", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def main():\n    outVideo = 'video/out.avi'\n    if os.path.exists(outVideo):\n        os.remove(outVideo)\n\n    camera = get_video()\n\n    people_list = []\n    inside_count = 0\n    outside_count = 0\n    frame_width = 640\n    frame_height = 480\n    prev_frame = 0\n\n    ret, img = camera.read()\n    if not ret:\n        print(\"Can't read video file!\")\n        exit(1)\n    else:\n        frame_height = len(img)\n        frame_width = len(img[0])\n    first_cap = True\n    if _OUTPUT_:\n        out = cv2.VideoWriter(outVideo, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n    msg = \"\"\n    nFrames = 0\n\n    while True:\n        ret, img = camera.read()\n        if not ret:\n            break\n        nFrames += 1\n        if nFrames < 250:\n            prev_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            continue\n\n        img = imutils.resize(img, width=640)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        peoples = top_cascade.detectMultiScale(gray, 1.1, 5, cv2.CASCADE_SCALE_IMAGE, \\\n                                               (SZ_LIMIT1, SZ_LIMIT1), (SZ_LIMIT2, SZ_LIMIT2))\n        # draw cross - line\n        cv2.line(img, line_point1, line_point2, (255, 0, 255), 2, 1)\n        \n        for (x, y, w, h) in peoples:\n\n            try:\n                frameDelta = cv2.absdiff(prev_frame[x:x + w - 1, y:y + h - 1], gray[x:x + w - 1, y:y + h - 1])\n                thresh1 = np.mean(frameDelta)\n            except (RuntimeError, TypeError, NameError):\n                continue\n            if thresh1 < 15:\n                continue", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#calulate center point\n            [cx, cy] = [x + w // 2, y + h // 2]\n\n            if cy < line_point1[1]-100:\n                continue\n            # draw detected rect\n            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 1)\n            cv2.circle(img, (cx, cy), 2, (0, 0, 255), 3)\n\n            lowest_closest_distance = float(\"inf\")\n            closest_person_index = None\n            rectangle_center = (cx, cy)\n\n            for i in range(0, len(people_list)):\n                dist = people_list[i].distance_from_last_x_positions(rectangle_center, 3)\n                if lowest_closest_distance > dist:\n                    lowest_closest_distance = dist\n                    closest_person_index = i\n            if lowest_closest_distance > 100:\n                closest_person_index = None\n            if closest_person_index is not None:\n                if lowest_closest_distance < LOWEST_CLOSEST_DISTANCE_THRESHOLD:\n                    people_list[i].update_position(rectangle_center)\n                    change = people_list[i].did_cross_line(line_point1[1])\n                    if change == ENTERED_STRING:\n                        inside_count += 1\n                    elif change == LEFT_AREA_STRING:\n                        # outside_count += 1\n                        pass\n                else:\n                    new_person = Person(rectangle_center)\n                    people_list.append(new_person)\n            else:\n                if rectangle_center[1] < line_point1[1]:\n                    continue\n                new_person = Person(rectangle_center)\n                people_list.append(new_person)\n       ", "execution_count": 32, "outputs": [{"output_type": "error", "ename": "SyntaxError", "evalue": "'continue' not properly in loop (cell_name, line 8)", "traceback": ["\u001b[0;36m  File \u001b[0;32m\"cell_name\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'continue' not properly in loop\n"]}]}, {"metadata": {}, "cell_type": "code", "source": "         # draw history\n        if _DEBUG_:\n            for i in range(0, len(people_list)):\n                pe = people_list[i]\n                for pos in range(0, len(pe.positions)):\n                    cv2.circle(img, pe.positions[pos], 1, (255, 255, 0), 2)\n\n        for candi in people_list:\n            if candi.isCounted:\n                # people_list.remove(candi)\n                pass\n\n        if first_cap:\n            first_cap = False\n\n        msg = \"In: {0}, Out: {1}\".format(inside_count, outside_count)\n        cv2.putText(img, msg, (10, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 255))\n\n        cv2.imshow('result', img)\n        if _OUTPUT_:\n            out.write(img)\n\n        prev_frame = gray\n\n        if _DEBUG_:\n            print(\"To continue, press key(c)\")\n            finish = False\n            while True:\n                k = cv2.waitKey(0) & 0xff\n                if k == ord('c'):\n                    break\n                elif k == 27:\n                    finish = True\n                    break\n                continue\n            if finish:\n                break\n        else:\n            k = cv2.waitKey(33) & 0xff\n            if k == 27:\n                break\n\n    camera.release()\n    if _OUTPUT_:\n        out.release()\n    cv2.destroyAllWindows()\n\n    print(msg)\n\n\nif __name__ == '__main__':\n    main()\n    print(\"Finished detection!\")", "execution_count": 34, "outputs": [{"output_type": "error", "ename": "IndentationError", "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)", "traceback": ["\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for i in range(0, len(people_list)):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}